<!DOCTYPE html> <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1.0"> <meta name=referrer  content=no-referrer  /> <title>Dynamic Trees with Alternative Search Trees - riteme.site</title> <link rel="shortcut icon" href="/favicon.png" type="image/png"> <link rel=stylesheet  href="/styles/material-icons.css"> <link rel=stylesheet  href="/styles/material.min.css" > <link rel=stylesheet  href="/styles/gitment.css"> <link rel=stylesheet  href="/math-renderer/katex/katex.min.css"> <link rel=stylesheet  href="/styles/site.css"> <script src="/scripts/jquery.min.js"></script> <script src="/scripts/js-cookie.js"></script> <script src="/scripts/quicklink.umd.js"></script> <script defer src="/scripts/material.min.js"></script> <script src="/scripts/site.js"></script> <script src="/scripts/gitment.js"></script> <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header"> <header class=mdl-layout__header > <div class=mdl-layout__header-row > <span class=mdl-layout-title >Dynamic Trees with Alternative Search Trees</span> <div class=mdl-layout-spacer ></div> <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right"> <label class="mdl-button mdl-js-button mdl-button--icon" for=fixed-header-drawer-exp ><i class=material-icons >search</i></label> <div class=mdl-textfield__expandable-holder > <form action="/search.html"><input type=text  class=mdl-textfield__input  placeholder="Search Here" name=q  id=fixed-header-drawer-exp  autocomplete=off  required></form> </div> </div> </div> </header> <div class=mdl-layout__drawer > <span class="mdl-layout-title drawer-title"> <a href="/index.html" style="color: inherit; font-weight: inherit;text-decoration: none;"><img src="/favicon.png" width=32 height=32> riteme.site</a> </span> <nav class=mdl-navigation > <a class=mdl-navigation__link  href="/index.html"><i class="material-icons drawer-icon">home</i> 首页</a> <a class=mdl-navigation__link  href="/posts.html"><i class="material-icons drawer-icon">library_books</i> 所有文章</a> <a class=mdl-navigation__link  href="/about.html"><i class="material-icons drawer-icon">info</i> 关于</a> <a class=mdl-navigation__link  href="/links.html"><i class="material-icons drawer-icon">link</i> 友链</a> <a class=mdl-navigation__link  href="/search.html"><i class="material-icons drawer-icon">search</i> 搜索</a> <a class=mdl-navigation__link  href="https://github.com/riteme/riteme.github.io"><i class="material-icons drawer-icon">class</i> GitHub 项目</a> </nav> </div> <main class=mdl-layout__content > <div class=mdl-grid > <div class="mdl-cell main-cell"> <div class="article main-article" lang=en-US > <h1 id=dynamic-trees-with-alternative-search-trees >Dynamic Trees with Alternative Search Trees</h1> <blockquote> <p>这篇文章实际上是这学期学术英语课的期末课程论文。写了点关于 LCT 的东西，试着将 Sleator 和 Tarjan 的用 biased tree 实现均摊 LCT 的证明改动了一下，希望能够证明 treap 也能做到一个 <tex>$\log$</tex> 的均摊复杂度。可能不是很严谨，但我觉得大致方向上没有问题。如果有问题欢迎提出来 QAQ</p> <p>文中实现的三种 LCT （biased tree, splay, treap）的代码：<a href="http://github.com/riteme/toys/tree/master/dynamic-trees">http://github.com/riteme/toys/tree/master/dynamic-trees</a></p> <p>原文 PDF：<a href=eap19-v3.pdf >eap19-v3.pdf</a></p> </blockquote> <p class=abstract ><strong>Abstract.</strong> We present an analysis for weighted treaps in link-cut trees (LCT) with amortized logarithmic time bounds and conduct an empirical study that investigates the discrepancies between different underlying data structures in LCT. We implemented three variants of LCT with biased search trees, self-adjusting search trees and weighted treaps and ran several experiments on them. Splay trees are the most efficient in LCT with amortized time bounds in our experiments while there is a <tex>$1.2$</tex> to <tex>$2$</tex> times slowdown in treaps and biased trees.<br /></p> <p class=keywords ><strong>Keywords:</strong> algorithms, data structures, dynamic trees, randomized search trees, self-adjusting search trees, biased search trees, experimental evaluation.<br /></p> <h3 id=1-introduction >1 Introduction</h3> <p>Dynamic tree problem focuses on the maintenance of a collection of trees under several operations, including adding an edge, removing an existing edge, designating tree roots (for rooted forest) and querying on the unique path between two nodes. Data can be stored on either nodes or edges. For simplicity, a new node can represent an edge in the original trees in order to put all data only on nodes. Dynamic trees have numerous applications especially in graph theory, such as network flows<sup id="fnref:G91"><a class=footnote-ref  href="#fn:G91" rel=footnote >13</a></sup><sup id="fnref:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup><sup id="fnref:T97"><a class=footnote-ref  href="#fn:T97" rel=footnote >23</a></sup> and dynamic graphs<sup id="fnref:C02"><a class=footnote-ref  href="#fn:C02" rel=footnote >8</a></sup><sup id="fnref:F85"><a class=footnote-ref  href="#fn:F85" rel=footnote >10</a></sup><sup id="fnref:F97a"><a class=footnote-ref  href="#fn:F97a" rel=footnote >11</a></sup><sup id="fnref:H99"><a class=footnote-ref  href="#fn:H99" rel=footnote >14</a></sup><sup id="fnref:R98"><a class=footnote-ref  href="#fn:R98" rel=footnote >18</a></sup>.<sup id="fnref:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup></p> <p>Dynamic tree problem has been well studied in literature, and there are many data structures that solve this problem, such as link-cut trees (LCT)<sup id="fnref2:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup><sup id="fnref:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup>, topology trees<sup id="fnref2:F85"><a class=footnote-ref  href="#fn:F85" rel=footnote >10</a></sup><sup id="fnref2:F97a"><a class=footnote-ref  href="#fn:F97a" rel=footnote >11</a></sup><sup id="fnref:F97b"><a class=footnote-ref  href="#fn:F97b" rel=footnote >12</a></sup>, Euler-tour trees (ETT)<sup id="fnref2:H99"><a class=footnote-ref  href="#fn:H99" rel=footnote >14</a></sup><sup id="fnref2:T97"><a class=footnote-ref  href="#fn:T97" rel=footnote >23</a></sup> and top trees<sup id="fnref:A97"><a class=footnote-ref  href="#fn:A97" rel=footnote >2</a></sup><sup id="fnref:A05"><a class=footnote-ref  href="#fn:A05" rel=footnote >3</a></sup><sup id="fnref:W06"><a class=footnote-ref  href="#fn:W06" rel=footnote >26</a></sup>. They all use search trees as underlying data structures but with different techniques: LCT uses path decomposition; ETT uses linearization; both topology trees and top trees use tree contraction.<sup id="fnref2:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup> LCT seems to be the first complete solution to the original dynamic tree problem and has been applied to many combinatorial algorithms. Although all the data structures guarantee logarithmic time bounds for most dynamic tree operations, their efficiency differs in many aspects, due to the overheads of non-sequential accesses, heavy memory allocations and huge constant factors hidden in the asymptotic complexities. Meanwhile, the choice of underlying data structures may have significant impacts on the performance of dynamic trees due to different methods of implementations. There have been some reports on the performance issues between various dynamic trees<sup id="fnref3:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup>, but there seem to be few investigations in underlying data structures. In our research, we attempted to conduct empirical studies on the discrepancies of underlying search trees in LCT. The reason for our choice of LCT is that LCT is one of the lightest data structures among all variants of dynamic trees, since the overheads are primarily from the <code class=op >Join</code> and <code class=op >Split</code> of search trees rather than LCT itself. In previous studies, researchers usually use biased search trees<sup id="fnref3:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> and splay trees<sup id="fnref2:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup> to maintain solid paths. The maintenance of solid paths relies heavily on biased searches, which implies alternatives such as weighted treaps<sup id="fnref:S96"><a class=footnote-ref  href="#fn:S96" rel=footnote >20</a></sup><sup id="fnref:B98"><a class=footnote-ref  href="#fn:B98" rel=footnote >7</a></sup>. In this paper, we provide an analysis for weighted treaps as implementation of underlying search trees in LCT, which should have amortized logarithmic time bounds.</p> <p>The remainder of this paper is organized as follows. Section 2 introduces dynamic tree problem and outlines the technique of path decomposition and LCT. Section 3 reviews biased search trees, splay trees and randomized search trees, i.e. treaps, in the setting of dynamic trees and we will sketch the proof for treaps in this section. Section 4 describes the platform setup used for comparisons and presents the experiments with discussions of results. The last section contains the overall conclusions and implications for further researches. Appendix A contains graph terminologies used in this paper.</p> <h3 id=2-dynamic-trees >2 Dynamic Trees</h3> <p><strong class=subsection >Dynamic Tree Problem.</strong> The original dynamic tree problem<sup id="fnref4:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> is aimed to maintain the structures of a collection of vertex-disjoint rooted trees under three kinds of operations: <code class=op >Link</code>, <code class=op >Cut</code> and <code class=op >Evert</code>. Initially there are <tex>$n$</tex> single-vertex trees and no edge in the forest.</p> <ul> <li><code class=op >Link</code><tex>$(x,\ y)$</tex>: Put a new edge <tex>$(x,\ y)$</tex> and thus combine two trees into one. For rooted forest, we designate the root of the original tree that contains node <tex>$x$</tex> as the root of the new tree. <li><code class=op >Cut</code><tex>$(x)$</tex>: Assuming that node <tex>$x$</tex> is not the tree root, remove the edge <tex>$(x,\ p(x))$</tex>, and thus divide the tree into two parts. One part contains <tex>$p(x)$</tex> and the other part contains <tex>$x$</tex> and <tex>$x$</tex> is the tree root. <li><code class=op >Evert</code><tex>$(x)$</tex>: Let node <tex>$x$</tex> be the new tree root. If <tex>$x$</tex> is already the tree root, it will be ignored. This operation actually does not alter the structure of the tree but changes the ancestor-descendant relations, making all other nodes the descendants of <tex>$x$</tex>. </ul> <p>In addition to operations that may alter tree structures, data can be associated with both nodes and edges, which enables queries on the chain between any two nodes. For simplicity, we can create new nodes to supersede the edges in original trees. Therefore, we can stored the data associated with edges on the corresponding nodes. Such simplification only leads to at most <tex>$n$</tex> new nodes, which has no effect on the asymptotic complexities. Thereby we assume only nodes may contain additional data.</p> <p><strong class=subsection >Path Decomposition.</strong> In this paper, we focus on <em>link-cut trees</em>, or LCT as the abbreviation, which was introduced by Sleator and Tarjan<sup id="fnref5:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> and uses a technique called <em>path decomposition</em>. In path decomposition, each edge is marked as either solid or dashed and we guarantee that no more than one solid edge entering any node (solid edge invariant). Consecutive solid edges form a solid path. It is trivial to see that any solid path is within an access path. Intuitively, solid paths do not bend in the tree that the depths of nodes along the path are monotone. In this way, a tree is decomposed into a set of solid paths connected by dashed edges. In the remainder of this paper, we use the notion <tex>$c(x)$</tex> to represent the chain containing <tex>$x$</tex>.</p> <div class=float-fig > <p><img src="https://riteme.site/blogimg/eap19/lct-1.svg"></p> <center class=figcaption >(a) An example of LCT. (b) LCT after <code class=op >Expose</code>$(x)$.</center> </div> <p>In order to implement basic dynamic tree operations, we need two fundamental operations:</p> <ul> <li><code class=op >Splice</code><tex>$(x)$</tex>: Provided that <tex>$x$</tex> is the topmost node of <tex>$c(x)$</tex> and not the tree root, if there is a solid edge from <tex>$p(x)$</tex>, we make this edge dashed. Thereby we are able to mark edge <tex>$(x,\ p(x))$</tex> as solid to connect <tex>$c(x)$</tex> and <tex>$c(p(x))$</tex> without violating the solid edge invariant. <li><code class=op >Expose</code><tex>$(x)$</tex>: Make the access path of <tex>$x$</tex> a solid path and all edges incident to this path dashed. This operation typically utilizes <code class=op >Splice</code>. </ul> <p>With <code class=op >Splice</code> and <code class=op >Expose</code>, other dynamic tree operations can be viewed as combinations of two operations.<sup id="fnref6:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup></p> <p>Since the depth of node in a solid path ascends from top to bottom, nodes can be kept in search trees such as biased search trees<sup id="fnref7:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> and self-adjusting search trees<sup id="fnref3:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup>. For <code class=op >Evert</code>, a reversal bit is supposed to be attached to each internal node in search trees. Because <code class=op >Splice</code> requires splitting and concatenating of search trees, we describe <code class=op >Split</code> and <code class=op >Join</code> formally as follows:</p> <ul> <li><code class=op >Split</code><tex>$(r,\ x)$</tex>: <tex>$r$</tex> is a search tree and <tex>$x$</tex> is the target node to be divided. We divide the tree into 1) at most three parts <tex>$(L,\ I,\ R)$</tex> where <tex>$L$</tex> denotes all nodes prior to <tex>$x$</tex> and <tex>$R$</tex> denotes all nodes after <tex>$x$</tex> and <tex>$I = \{x\}$</tex> if <tex>$x$</tex> exists in the search tree and otherwise <tex>$I = \varnothing$</tex> (3-way <code class=op >Split</code>); 2) two parts <tex>$(L,\ R)$</tex> where <tex>$L$</tex> denotes all nodes prior to <tex>$x$</tex> and <tex>$x$</tex> itself if existed and <tex>$R$</tex> denotes all nodes after <tex>$x$</tex> (2-way <code class=op >Split</code>). In both cases, <tex>$L$</tex> and <tex>$R$</tex> are still search trees. <li><code class=op >Join</code>: Given two search trees <tex>$x$</tex> and <tex>$y$</tex> where all elements in <tex>$x$</tex> precede those in <tex>$y$</tex> (2-way <code class=op >Join</code><tex>$(x,\ y)$</tex>), or two search trees <tex>$x$</tex> and <tex>$y$</tex> along with a new node <tex>$k$</tex> placed between the last node of <tex>$x$</tex> and the first node of <tex>$y$</tex> (3-way <code class=op >Join</code><tex>$(x,\ y,\ k)$</tex>), they are merged into one search tree with correct connections. A 3-way join is usually interpreted into two 2-way joins. </ul> <p><strong>Remark.</strong> Biased trees only support 2-way splits and 2-way joins while self-adjusting trees allow both variants of splits and joins.</p> <p>One of the most prominent properties of LCT is illustrated by the following theorem.</p> <p><strong class=theorem >Theorem 1.</strong> If the overall number of <code class=op >Link</code>, <code class=op >Cut</code> and <code class=op >Expose</code> is <tex>$m$</tex>, then there are at most <tex>$m(3\lfloor \log n \rfloor + 1)$</tex> <code class=op >Splice</code>.<sup id="fnref8:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup></p> <p><strong class=corollary >Corollary 1.</strong> If the time complexity of <code class=op >Splice</code> is <tex>$\mathrm O(f(n))$</tex>, then <code class=op >Link</code>, <code class=op >Cut</code>, <code class=op >Evert</code> and <code class=op >Expose</code> take <tex>$\mathrm O(f(n)\log n)$</tex> amortized time. Particularly, LCT has <tex>$\mathrm O(\log^2 n)$</tex> amortized time bounds with arbitrary acceptable search trees with logarithmic time bounds.</p> <p><strong>Proof.</strong> Directly derived from Theorem 1.<qed></p> <h3 id=3-reviews-and-analyses >3 Reviews and Analyses</h3> <p>Among three schemes of LCT, the concept of <em>ranks</em> is used in analyses. The rank of <tex>$x$</tex>, or <tex>$r(x)$</tex>, usually equals to <tex>$\Theta(\log s(x))$</tex>. In amortized analysis, ranks can be viewed as credits assigned to nodes and therefore ranks are supposed to be non-negative values. One credit can be used to perform a <tex>$\Theta(1)$</tex> procedure so that the overall running time is measured by the number of credits allocated in the algorithm. In order to evaluate ranks, we shall associate each node with a weight <tex>$w(x)$</tex> explicitly or implicitly, where</p> <p><tex>$$ w(x) = \begin{cases} s(x) - s(u) &amp; (\text{if solid edge from } x \text{ enters } u) \\ s(x) &amp; (\text{otherwise}) \end{cases} $$</tex></p> <p>and then <tex>$s(x)$</tex> can be calculated by aggregating over the subtree <tex>$x$</tex> in search tree. We may update weights in <code class=op >Splice</code> and other operations that may alter the tree structure. LCT keeps the invariant that total weight of an underlying search tree equals to the size of corresponding subtree.</p> <p><strong class=subsection >Biased Search Trees.</strong> Bent et al.<sup id="fnref:B85"><a class=footnote-ref  href="#fn:B85" rel=footnote >4</a></sup> proposed biased <tex>$2$</tex>-<tex>$b$</tex> trees and Feigenbaum et al.<sup id="fnref:F83"><a class=footnote-ref  href="#fn:F83" rel=footnote >9</a></sup> refined their work and examined biased <tex>$a$</tex>-<tex>$b$</tex> trees. Biased trees are intended to solve biased dictionary problem<sup id="fnref2:F83"><a class=footnote-ref  href="#fn:F83" rel=footnote >9</a></sup>, where items are assigned with access frequencies, i.e. weights, and the search tree is restructured based on the weights in order to achieve minimal total access time. In biased trees, an access to <tex>$x$</tex> takes <tex>$\mathrm O(\log W/w(x))$</tex> time, where <tex>$W$</tex> is the overall weight in search tree. Such accesses are called ideal accesses<sup id="fnref2:B85"><a class=footnote-ref  href="#fn:B85" rel=footnote >4</a></sup><sup id="fnref3:F83"><a class=footnote-ref  href="#fn:F83" rel=footnote >9</a></sup>. Bent et al.<sup id="fnref3:B85"><a class=footnote-ref  href="#fn:B85" rel=footnote >4</a></sup> showed that <code class=op >Join</code><tex>$(x,\ y)$</tex> takes only <tex>$|r(x) - r(y)| + 1$</tex> credits and the amortized time to <code class=op >Split</code> at node <tex>$x$</tex> is proportional to the access time to <tex>$x$</tex>. These time bounds are excellent and with a careful analysis on credit changes in <code class=op >Expose</code>, Sleator et al.<sup id="fnref9:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> proved that the amortized running time over a sequence of <tex>$m$</tex> dynamic tree operations is <tex>$\mathrm O(m \log n)$</tex>. Although biased trees are the first data structures applied to dynamic trees, the complicated case analysis<sup id="fnref4:B85"><a class=footnote-ref  href="#fn:B85" rel=footnote >4</a></sup> leads to the inefficiency of biased trees. Thus biased trees are not preferred in dynamic trees.</p> <p><strong class=subsection >Splay Trees.</strong> One of the most well-known self-adjusting search trees is the splay tree, introduced by Sleator and Tarjan<sup id="fnref4:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup>. Compared to conventional search trees such as AVL tree and red-black tree, both of which rely on extra information maintained in search tree nodes to preserve low tree height, splay tree adjusts itself by tree rotations whenever accessed and manages to gather all frequently accessed nodes in the vicinity of search tree root, optimizing for future accesses. Splay trees utilize a variation of move-to-root heuristic<sup id="fnref:B79"><a class=footnote-ref  href="#fn:B79" rel=footnote >5</a></sup>, i.e. the so-called <code class=op >Splay</code>, that unexpectedly improves the performance. The original move-to-root heuristic simply moves the node to root by rotating once at each step, while <code class=op >Splay</code> may rotate at most twice at each step. Provided that all splay tree operations are based on <code class=op >Splay</code>, the only non-trivial work is to devise the upper bound of rotations in <code class=op >Splay</code>, which is depicted by the Access Lemma<sup id="fnref5:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup>.</p> <p><strong class=lemma >Lemma 1.</strong> (Access Lemma) The amortized time to splay a tree with root <tex>$t$</tex> at a node <tex>$x$</tex> is at most <tex>$3(r(t) - r(x)) + 1 = \mathrm O(\log s(t)/s(x))$</tex>.<sup id="fnref6:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup></p> <p>The magic <code class=op >Splay</code> actually predicts the weight of each node based on previous accesses instead of keeping them explicitly. The wonderful property of implicit weights enables us to obtain heterogeneous time bounds under different circumstances without the great cost of “re-weighting”. Splay trees have been integrated into LCT to allow simple and efficient implementations and Sleator et al.<sup id="fnref7:S85"><a class=footnote-ref  href="#fn:S85" rel=footnote >22</a></sup> showed that such LCT achieved amortized logarithmic time bounds. However, splay trees show a significant increase in changes to tree structures, which contributes to the huge overheads of node updating and slows down splay trees when accesses are the primary operations, since other search trees do not alter the tree structure while accessing.</p> <p><strong class=subsection >Randomized Search Trees.</strong> Seidel and Aragon<sup id="fnref2:S96"><a class=footnote-ref  href="#fn:S96" rel=footnote >20</a></sup> thoroughly explored randomizations in balanced search trees and coined the term “treap” for search trees with random priorities on nodes. In addition to obeying symmetric order of search trees, treaps use tree rotations to stipulate that nodes with larger priorities are not descendants of those with smaller priorities. Seidel<sup id="fnref3:S96"><a class=footnote-ref  href="#fn:S96" rel=footnote >20</a></sup> claimed that an access to <tex>$x$</tex> can be completed in expected <tex>$\mathrm O(\log W/w(x))$</tex> time if we take the maximum value of <tex>$w(x)$</tex> randomly generated numbers as the priority for each <tex>$x$</tex>, or store <tex>$(\log r) / w(x)$</tex> instead for priority comparisons where <tex>$r$</tex> is randomly generated. Weighted treaps are our main concerns, since they support ideal accesses. The first method mentioned above does not support fast re-weighting while the second method involves floating point numbers that are not as efficient as fixed-size integers on modern computers, so we prefer <em>implicit priorities</em> in this paper, which are simulated according to subtree sizes. In <code class=op >Join</code><tex>$(x,\ y)$</tex>, we toss a coin with bias <tex>$p = s(x) / (s(x) + s(y))$</tex> so that the probability that the priority of <tex>$x$</tex> is larger than that of <tex>$y$</tex> is <tex>$p$</tex>. Assuming that priorities have already computed in <code class=op >Join</code>, implicit priorities are equivalent to ordinary priorities in analysis.</p> <p>Applying weighted treaps to LCT is feasible, as we will show in the remainder of this section. In our analysis, any node can represent the treap containing it, and <tex>$s(x)$</tex> is the overall weight in the treap <tex>$x$</tex>, even if <tex>$x$</tex> is not the tree root. Let <tex>$r(x) = \log s(x)$</tex> and <tex>$m$</tex> be the number of dynamic tree operations. We distinguish <em>special splices</em> from <em>normal splices</em> that a special splice at <tex>$x$</tex> marks a new solid edge <tex>$(x,\ p(x))$</tex> when <tex>$p(x)$</tex> is the tail of <tex>$c(p(x))$</tex>, rather than switching solid edges in normal splices.</p> <p><img alt="" src="https://riteme.site/blogimg/eap19/splice-1.svg" /><br /> <center class=figcaption >Special splice (left) and normal splice (right). Both splice at <tex>$x$</tex> and the edge <tex>$(x,\ p(x))$</tex> will be solid.</center></p> <p>Since every special splice induces a new solid edge, it is suggested that there seem to be few special splices. Sleator et al.<sup id="fnref10:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> showed that there are at most <tex>$m$</tex> special splices, i.e. one <code class=op >Splice</code> per <code class=op >Expose</code> on average. It indicates that special splices are not the major overheads in <code class=op >Expose</code>. To carry out the amortized analysis, we store <tex>$\Theta(r(x) - r(y))$</tex> <em>credits</em> on each node <tex>$y$</tex> where <tex>$x$</tex> is the parent of <tex>$y$</tex> in treap. Meanwhile, the root of a treap may also have credits. We say treap <tex>$u$</tex> is <em>cast to</em> <tex>$c \geqslant r(u)$</tex> iff. <tex>$\Theta(c - r(u))$</tex> credits have been allocated on <tex>$u$</tex>. We often refer to these two properties as <em>credit invariants</em>. We will devise two key properties pertaining to <code class=op >Join</code> and <code class=op >Split</code>. Proofs for the next two lemmas are deferred to Appendix B and Appendix C.</p> <p><strong class=lemma >Lemma 2.</strong> (Join Lemma) If treap <tex>$z$</tex> is obtained by <code class=op >Join</code><tex>$(x,\ y,\ k)$</tex> and both treap <tex>$x$</tex> and treap <tex>$y$</tex> are cast to <tex>$c \geqslant r(z)$</tex>, then treap <tex>$z$</tex> is also cast to <tex>$c$</tex>. <tex>$\Theta(c - r(k))$</tex> new credits are required to perform the <code class=op >Join</code>.</p> <p><strong class=lemma >Lemma 3.</strong> (Split Lemma) Treap <tex>$u$</tex> and treap <tex>$v$</tex> are obtained via <code class=op >Split</code><tex>$(x,\ y)$</tex>. If treap <tex>$x$</tex> is cast to <tex>$c \geqslant r(x)$</tex> and we allocate <tex>$\Theta(c - \log w(y))$</tex> credits, both treap <tex>$u$</tex> and treap <tex>$v$</tex> are cast to <tex>$c$</tex>.</p> <p>Finally we investigate credit changes in <code class=op >Expose</code>.</p> <p><strong class=lemma >Lemma 4.</strong> (Expose Lemma) <code class=op >Expose</code> takes <tex>$\mathrm O(\log n)$</tex> amortized time.</p> <p><strong>Proof.</strong> We interpret <code class=op >Expose</code><tex>$(u_0)$</tex> into four phases.</p> <p>(1) Setup: Turn the solid edge from <tex>$u_0$</tex> to dashed by a 2-way <code class=op >Split</code>. It takes <tex>$\mathrm O(\log n)$</tex> time.</p> <p>(2) Split Phase: Traverse from <tex>$u_0$</tex> to the tree root and label the head nodes of visited chains with <tex>$u_1,\ u_2,\ ...,\ u_p$</tex> (<tex>$u_p$</tex> is the tree root). Parents of them are <tex>$v_1,\ v_2,\ ...,\ v_{p - 1}$</tex> and <tex>$\varnothing$</tex>. In step <tex>$i$</tex>, we <code class=op >Split</code> at <tex>$v_i$</tex> and thus <tex>$c(v_i)$</tex> is divided into at most three parts represented by <tex>$u_{i + 1}$</tex> (possibly empty), <tex>$v_i$</tex> and <tex>$q_i$</tex> (for normal splices). Let <tex>$k$</tex> be the number of special splices in <code class=op >Expose</code><tex>$(u_0)$</tex> and <tex>$r'(u_{i+1})$</tex>, <tex>$r'(v_i)$</tex>, <tex>$r'(q_i)$</tex> be the ranks of <tex>$u_{i+1}$</tex>, <tex>$v_i$</tex>, <tex>$q_i$</tex> respectively after <code class=op >Split</code>. Note that <tex>$k = \mathrm O(1)$</tex> in amortized sense and <tex>$r'(v_i) \geqslant r(u_i)$</tex>. Treap <tex>$u_{i + 1}$</tex> prior to <code class=op >Split</code> is obviously cast to <tex>$r(u_{i + 1})$</tex>. Split Lemma implies that it takes only <tex>$\mathrm O(r(u_{i + 1}) - r'(v_i)) = \mathrm O(r(u_{i +1}) - r(u_i))$</tex> amortized time for both special and normal splices. If the splice is normal, it leaves <tex>$\Theta(r(u_{i + 1}) - r'(q_i))$</tex> credits on <tex>$q_i$</tex>.</p> <p><img alt="" src="https://riteme.site/blogimg/eap19/expose-1.svg" /><br /> <center class=figcaption >(a) Prior to Split Phase. (b) After Split Phase. (c) An example of normal splice during step <tex>$i$</tex>.</center></p> <p>(3) Re-weight: <tex>$w(v_i)$</tex> is changed to <tex>$s(v_i) - s(u_i)$</tex>. Let <tex>$r''(v_i)$</tex> be the new rank of <tex>$v_i$</tex>. It takes constant time.</p> <p>(4) Join Phase: Perform 3-way <code class=op >Join</code><tex>$(u_{i + 1},\ u_i,\ v_i)$</tex> in step <tex>$i$</tex>. We have to place <tex>$\Theta(r(u_{i+1}) - r(u_i))$</tex> credits on <tex>$u_i$</tex> to make treap <tex>$u_i$</tex> cast to <tex>$r(u_{i+1})$</tex> and thereby <code class=op >Join</code> only takes <tex>$\mathrm O(r(u_{i+1}) - r''(v_i))$</tex> amortized time by Join Lemma. In normal splices, saved credits from <tex>$q_i$</tex> can eliminate the time consumed by <code class=op >Join</code> since <tex>$r''(v_i) \geqslant r'(q_i)$</tex>. Therefore only special splice takes additional <tex>$\mathrm O(r(u_{i+1}) - r''(v_i)) = \mathrm O(\log n)$</tex> time.</p> <p>The sum of costs of all steps telescopes and gives a bound of <tex>$\mathrm O(p + r(u_p) - r(u_1) + (k + 1)\log n)$</tex>. By Theorem 1 and the fact <tex>$k = \mathrm O(1)$</tex> and the definition of rank, the bound turns out to be <tex>$\mathrm O(\log n)$</tex>.<qed></p> <p>Our result is stated by the following theorem, which is derived immediately from Expose Lemma.</p> <p><strong class=theorem >Theorem 2.</strong> If weighted treaps are used as underlying data structures in LCT, then all dynamic tree operations have amortized <tex>$\mathrm O(\log n)$</tex> upper bounds with high probability.</p> <p>Finally we emphasize that the bounds are not averaged on worst-case operation sequences due to the randomness of treaps.</p> <h3 id=4-experiments >4 Experiments</h3> <p><strong class=subsection >Experimental Setup.</strong> In this section we present an empirical study of impacts of different underlying data structures on LCT. Three kinds of search trees are used: biased 2-3 trees (biased), self-adjusting search trees (splay) and randomized search trees (treap). We tested all algorithms for minimum spanning forest problem (MSF) along with Kruskal&rsquo;s <tex>$\mathrm O(m \log m)$</tex> algorithm<sup id="fnref:K56"><a class=footnote-ref  href="#fn:K56" rel=footnote >15</a></sup> (kruskal) as the standard program to ensure the correctness of our algorithms. Here <tex>$n$</tex> is the number of vertices in graph and <tex>$m$</tex> denotes the number of edges. All algorithms were implemented in C++ by the authors and are available at <code class=url >http://github.com/riteme/toys/tree/master/dynamic-trees</code>. Source code was compiled by Clang 6.0.0 with <code>-O3 -Ofast -DNDEBUG</code> options for full optimizations. Experiments were carried out on Intel™ i5 8300H running Ubuntu 18.04 (64bit operating system, Linux Kernel 4.20.13, Xorg not started) at 4.0GHz in a single core, with 128KB L1 data cache, 1MB L2 cache, 8MB L3 cache and 16GB RAM. CPU time was measured with <code>high_resolution_clock</code> from Standard Template Library (STL) in C++ with 1ns precision. Each individual execution was repeated until the number of processed edges exceeded <tex>$5×10^6$</tex> and we took the average on all edges. An untimed execution prior to timed runs for each algorithm was aimed to warm up the cache and prevent inconsistent result in the first run. Test data were generated by pseudo-random generator (<code>rand</code> in GNU C library) and we randomly chose seeds obtained from <code>random_device</code> in STL to generate five different inputs for each set of parameters and report the average results. Time for initialization, finalization and reading files was not accounted.</p> <p>In LCT-based solutions, <tex>$m$</tex> edges are added into an initially empty graph one by one and we maintain the MSF as dynamic trees. When processing an edge <tex>$(u,\ v,\ w)$</tex> (<tex>$w$</tex> is the length of the edge), if <tex>$u$</tex> and <tex>$v$</tex> are not in the same components, this edge will be immediately added. Otherwise there is a chain between <tex>$u$</tex> and <tex>$v$</tex> in dynamic trees. In this case, we pick up the longest edge <tex>$(u,\ v,\ w_0)$</tex> in the chain from <tex>$u$</tex> to <tex>$v$</tex>. If <tex>$w_0 \geqslant w$</tex>, the longest edge will be discarded by <code class=op >Cut</code> and the new edge will be incorporated into dynamic trees via <code class=op >Link</code>. The new edge will be ignored if <tex>$w_0 \leqslant w$</tex> and we continue to process the next edge. This procedure can be implemented in <tex>$\mathrm O(\log n)$</tex> amortized time by LCT.</p> <p>Three solutions based on LCT used the same interface exported to the main program to guarantee uniformity. Treaps utilized Xorshift algorithm<sup id="fnref:M03"><a class=footnote-ref  href="#fn:M03" rel=footnote >16</a></sup> for extremely fast pseudo-random generations. Biased trees required extra memory for internal nodes and we implemented a stack-based memory pool for biased trees. All solutions were implemented in non-recursive fashion.</p> <div class=float-fig > <p><img src="https://riteme.site/blogimg/eap19/result.svg"></p> <center class=figcaption >Experimental results. (a) Figure for randomized test data. (b) Figure for cache tests. Horizontal axes are scaled by binary logarithm and time is measured in microseconds averaged on all edges.</center> </div> <p><strong class=subsection >Random Data.</strong> We first tested on randomly generated graphs. Random graphs were obtained by generating <tex>$m$</tex> edges <tex>$(u_i,\ v_i,\ w_i)$</tex> where both <tex>$u_i$</tex> and <tex>$v_i$</tex> are distinct and randomly chosen from <tex>$[1..n]$</tex> and <tex>$w_i$</tex> is the length of edge <tex>$i$</tex> and within <tex>$[1..10^9]$</tex>. In this experiment, <tex>$n$</tex> varied from <tex>$2^{10}$</tex> to <tex>$2^{20}$</tex> and <tex>$m$</tex> was set to <tex>$8n$</tex>. Results are shown in Fig.4. (a). It suggests that biased trees are the slowest among all solutions, taking approximately twice the time of splay trees, while treaps show competitively performance compared to splay trees. Kruskal&rsquo;s algorithm is the fastest owing to its simplicity and the efficient implementation of quick sort algorithm in STL. Nearly identical figures between treaps and splay trees are consonant to Theorem 2. Furthermore, our results are also consistent with Pfaff&rsquo;s conclusion<sup id="fnref:P04"><a class=footnote-ref  href="#fn:P04" rel=footnote >17</a></sup> that splay trees outperform conventional binary search trees such as AVL trees and red-black trees in system softwares. We assume that splay trees are advantageous in the setting of amortized LCT since the data structure is ephemeral and changes even during accesses. The results offer a different aspect of prominent performance of splay-based LCT as suggested by Tarjan et al.<sup id="fnref4:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup> in experiments among various types of dynamic trees.</p> <p><strong class=subsection >Cache Tests.</strong> Since the time complexity is logarithmic in theory, figures are expected to be linear. However, we noticed that figures approximately comprise two linear functions. Such peculiar phenomena was observed by Tarjan et al.<sup id="fnref5:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup> as well and they deduced that cache-missing contributes to the increased slopes in right parts of figures. We attempted to examine the impacts of cache by a new data generator. We fixed <tex>$B = 2^9 = 512$</tex> as the block size and <tex>$n = cB$</tex> and <tex>$m = 8n$</tex>, where <tex>$c$</tex> is the number of blocks. The only difference from the previous random generator is that we first choose a block for each edge rather than putting it arbitrarily. The inputs can be viewed as a sequence of small graphs with size <tex>$B$</tex>, and now algorithms cannot concentrate on a single block but switching frequently between blocks. Accesses to RAM are time-consuming and much slower than operating on cache. When <tex>$c$</tex> increases, data may not completely fit in the cache and thus force CPU to access RAM, i.e. cache-missing. Fig.4. (b) reports that when <tex>$c \leqslant 2^7$</tex> (<tex>$n \leqslant 2^{16}$</tex>), the relative increments of time are less than <tex>$27\%$</tex> for three trees, in contrast to nearly <tex>$90\%$</tex> in Fig.4. (a) when <tex>$n$</tex> varies from <tex>$2^{10}$</tex> to <tex>$2^{16}$</tex>. Significant increases after <tex>$c = 2^7$</tex> (<tex>$c = 2^8$</tex> for splay trees) demonstrate that the dominant performance-dropping factor seems to be the limited cache size. For example, the size of node in LCT with treaps is <tex>$36$</tex> bytes in our implementation and therefore the total memory allocated is <tex>$2×2^8×512×36 = 9,437,184$</tex> bytes when <tex>$c = 2^8$</tex>, which cannot fit in an 8MB L3 cache anymore. Note that edges are replaced with new nodes in dynamic trees so the actual number of nodes is <tex>$2n$</tex>. For splay trees, this amount decreases to only <tex>$7,340,032$</tex> bytes so that splay-based LCT can be preloaded into cache. Biased trees are slowed down by the huge extra memory consumption from internal nodes for similar reasons. We conclude that the advantage of no extra information in splay tree nodes makes splay tree more cache-friendly and contributes to its amazing performance. With smaller cache size, Tarjan et al.<sup id="fnref6:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup> provided a more detailed figure when <tex>$c$</tex> gets larger and we speculate that the growth rate will eventually converges to a constant due to the tendency to direct manipulations of data in RAM. Meanwhile, our platform has an extra 1MB L2 cache compared to Tarjan&rsquo;s experiments<sup id="fnref7:T10"><a class=footnote-ref  href="#fn:T10" rel=footnote >25</a></sup> which may accelerate algorithms when <tex>$n \leqslant 2^{12}$</tex> and enlarge the discrepancies for <tex>$n \leqslant 2^{16}$</tex>.</p> <h3 id=5-conclusions-and-discussions >5 Conclusions and Discussions</h3> <p>In this paper, we reviewed and briefly analyzed three schemes to implement link-cut trees in amortized logarithmic time. They share an identical interface to users and only differ in the underlying data structures. It is mainly an interest of theoretical research to devise alternatives in amortized LCT because empirical study has demonstrated that splay-based version is the most efficient and other ordinary search trees take no advantage in an ever-changing data structure and splay trees are more memory-friendly and cache-friendly in the comparisons. Werneck<sup id="fnref2:W06"><a class=footnote-ref  href="#fn:W06" rel=footnote >26</a></sup> mentioned that Alstrup et al. attempted to implement LCT with weighted treaps and compared its performance to splay-based LCT, but their experimental part is unpublished. However, if we need to keep historical versions of dynamic trees, LCT must guarantee worst-case time complexities instead of amortized ones. Sleator et al.<sup id="fnref11:S81"><a class=footnote-ref  href="#fn:S81" rel=footnote >21</a></sup> presented a modified version of biased trees, i.e. globally-biased <tex>$2$</tex>-<tex>$b$</tex> trees<sup id="fnref4:F83"><a class=footnote-ref  href="#fn:F83" rel=footnote >9</a></sup>, that ensures worst-case performance of LCT. We leave it as an open problem that whether there is an alternative to globally-biased trees in LCT with worst-case time bounds.</p> <h3 id=appendixes >Appendixes</h3> <p><strong>A. Graph Terminology.</strong> In graph theory, a <em>graph</em> <tex>$G = (V,\ E)$</tex> consists of a set of vertices or nodes (represented by <tex>$V$</tex>) and a set of edges connecting them (represented by <tex>$E$</tex>). We may assume <tex>$n = |V|$</tex> in analysis. A graph is <em>connected</em> iff. any two nodes are connected by a <em>path</em>. A <em>tree</em> is a connected graph with exactly <tex>$n - 1$</tex> edges and a <em>forest</em> consists of some tree-like components. It is obvious that the number of edges in a forest is strictly less than <tex>$n$</tex>. One important characteristic of trees is that there is only one simple path connecting any two nodes, and we often refer to those unique paths as <em>chains</em>. In some applications, we choose a node as <em>tree root</em> for each tree, i.e. <em>rooted trees</em>, in contrast to <em>free trees</em>. In rooted trees, <em>access path</em> of node <tex>$x$</tex> is the chain from <tex>$x$</tex> to tree root, and all the nodes in this path are called <em>ancestors</em> of <tex>$x$</tex>. Note that <tex>$x$</tex> is also an ancestor of itself. Meanwhile, <tex>$y$</tex> is a <em>descendant</em> of <tex>$x$</tex> iff. <tex>$x$</tex> is an ancestor of <tex>$y$</tex>. All descendants of <tex>$x$</tex> as well as the edges between them form a <em>subtree</em> rooted at <tex>$x$</tex> (including <tex>$x$</tex> itself). For convenience, we often use the subtree root to refer to the entire subtree. Specially, for edge <tex>$(x,\ y)$</tex>, if <tex>$x$</tex> is an ancestor of <tex>$y$</tex>, then <tex>$x$</tex> is also called the <em>parent</em> of <tex>$y$</tex> or <tex>$x = p(y)$</tex> and <tex>$y$</tex> is a child of <tex>$x$</tex>. For tree root <tex>$r$</tex>, <tex>$p(r)$</tex> is defined to be <tex>$\varnothing$</tex>. The <em>depth</em> of <tex>$x$</tex> is the number of nodes in the access path of <tex>$x$</tex>, and <tex>$s(x)$</tex> stands for the number of vertices in the subtree <tex>$x$</tex>.</p> <p><strong>B. Proof for Join Lemma.</strong> Consider the <em>right spine</em> of treap <tex>$x$</tex> (<em>left spine</em> of treap <tex>$y$</tex>) during <code class=op >Join</code>. <code class=op >Join</code> will end up node <tex>$k$</tex> reaching its appropriate position with two subtrees <tex>$x_0$</tex> and <tex>$y_0$</tex> (possibly empty). Let <tex>$r'(k)$</tex> be the rank of <tex>$k$</tex> after <code class=op >Join</code>. The time to travel on both spines is <tex>$\mathrm O(\log s(z) / w(k)) = \mathrm O(r(z) - r(k)) = \mathrm O(c - r(k))$</tex> by ideal access. To maintain credit invariants, we observe that the number of required credits summing over <tex>$z$</tex> to <tex>$k$</tex> is <tex>$\Theta(c - r'(k))$</tex> by telescoping, which is not greater than the newly allocated credits since <tex>$r'(k) \geqslant r(k)$</tex>, and credits on <tex>$x_0$</tex> can be compensated by the <tex>$\Theta(c - r(x_0))$</tex> credits aggregated over <tex>$x$</tex> to <tex>$x_0$</tex> in original treap <tex>$x$</tex> since <tex>$c \geqslant r(z) \geqslant r'(k)$</tex>. Arguments for <tex>$y_0$</tex> are similar.<qed></p> <p><strong>C. Proof for Split Lemma.</strong> <code class=op >Split</code> is the inverse of <code class=op >Join</code> (figure omitted). Let <tex>$r'(y) = \log w(y)$</tex>. The time to access <tex>$y$</tex> is <tex>$\mathrm O(\log s(x) / w(y)) = \mathrm O(r(x) - r'(y)) = \mathrm O(c - r'(y))$</tex>. Suppose <tex>$y$</tex> has two children <tex>$u_0$</tex> and <tex>$v_0$</tex> (possibly empty). <tex>$\Theta(c - r(u_0))$</tex> credits aggregated over <tex>$x$</tex> to <tex>$u_0$</tex> are distributed on all nodes from <tex>$u$</tex> to <tex>$u_0$</tex> to guarantee that treap <tex>$u$</tex> is cast to <tex>$c$</tex>. <tex>$\Theta(c - r(y)) = \mathrm O(c - r'(y))$</tex> new credits are supplied to treap <tex>$v$</tex>. Along with the original <tex>$\Theta(r(y) - r(v_0))$</tex> credits on <tex>$v_0$</tex>, the final <tex>$\Theta(c - r(v_0))$</tex> credits are sufficient to ensure treap <tex>$v$</tex> is also cast to <tex>$c$</tex>.<qed></p> <div class=float-fig > <p><img src="https://riteme.site/blogimg/eap19/join-1.svg"></p> <center class=figcaption >An example of <code class=op >Join</code>. (a) Left spine and right spine. (b) Treap $z$ after <code class=op >Join</code>. Dashed edges are removed during <code class=op >Join</code>.</center> </div> <div class=footnote > <hr /> <ol> <li id="fn:A04"> <p>U. A. Acar, G. E. Blelloch, R. Harper, J. L. Vittes, and S. L. M. Woo, “Dynamizing Static Algorithms, with Applications to Dynamic Trees and History Independence,” in <em>Proceedings of the Fifteenth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, Philadelphia, PA, USA, 2004, pp. 531–540.&#160;<a class=footnote-backref  href="#fnref:A04" rev=footnote  title="Jump back to footnote 1 in the text">&#8617;</a></p> <li id="fn:A97"> <p>S. Alstrup, J. Holm, K. de Lichtenberg, and M. Thorup, “Minimizing Diameters of Dynamic Trees,” in <em>Automata, Languages and Programming</em>, 1997, pp. 270–280.&#160;<a class=footnote-backref  href="#fnref:A97" rev=footnote  title="Jump back to footnote 2 in the text">&#8617;</a></p> <li id="fn:A05"> <p>S. Alstrup, J. Holm, K. D. Lichtenberg, and M. Thorup, “Maintaining Information in Fully Dynamic Trees with Top Trees,” <em>ACM Trans. Algorithms</em>, vol. 1, no. 2, pp. 243–264, Oct. 2005.&#160;<a class=footnote-backref  href="#fnref:A05" rev=footnote  title="Jump back to footnote 3 in the text">&#8617;</a></p> <li id="fn:B85"> <p>S. Bent, D. Sleator, and R. Tarjan, “Biased Search Trees,” <em>SIAM J. Comput.</em>, vol. 14, no. 3, pp. 545–568, Aug. 1985.&#160;<a class=footnote-backref  href="#fnref:B85" rev=footnote  title="Jump back to footnote 4 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:B85" rev=footnote  title="Jump back to footnote 4 in the text">&#8617;</a><a class=footnote-backref  href="#fnref3:B85" rev=footnote  title="Jump back to footnote 4 in the text">&#8617;</a><a class=footnote-backref  href="#fnref4:B85" rev=footnote  title="Jump back to footnote 4 in the text">&#8617;</a></p> <li id="fn:B79"> <p>J. Bitner, “Heuristics That Dynamically Organize Data Structures,” <em>SIAM J. Comput.</em>, vol. 8, no. 1, pp. 82–110, Feb. 1979.&#160;<a class=footnote-backref  href="#fnref:B79" rev=footnote  title="Jump back to footnote 5 in the text">&#8617;</a></p> <li id="fn:B16"> <p>G. E. Blelloch, D. Ferizovic, and Y. Sun, “Just Join for Parallel Ordered Sets,” in <em>Proceedings of the 28th ACM Symposium on Parallelism in Algorithms and Architectures</em>, New York, NY, USA, 2016, pp. 253–264.&#160;<a class=footnote-backref  href="#fnref:B16" rev=footnote  title="Jump back to footnote 6 in the text">&#8617;</a></p> <li id="fn:B98"> <p>G. E. Blelloch and M. Reid-Miller, “Fast Set Operations Using Treaps,” in <em>Proceedings of the Tenth Annual ACM Symposium on Parallel Algorithms and Architectures</em>, New York, NY, USA, 1998, pp. 16–26.&#160;<a class=footnote-backref  href="#fnref:B98" rev=footnote  title="Jump back to footnote 7 in the text">&#8617;</a></p> <li id="fn:C02"> <p>G. Cattaneo, P. Faruolo, U. F. Petrillo, and G. F. Italiano, “Maintaining Dynamic Minimum Spanning Trees: An Experimental Study,” in <em>Algorithm Engineering and Experiments</em>, 2002, pp. 111–125.&#160;<a class=footnote-backref  href="#fnref:C02" rev=footnote  title="Jump back to footnote 8 in the text">&#8617;</a></p> <li id="fn:F83"> <p>J. Feigenbaum and R. E. Tarjan, “Two New Kinds of Biased Search Trees,” <em>The Bell System Technical Journal</em>, vol. 62, no. 10, pp. 3139–3158, Dec. 1983.&#160;<a class=footnote-backref  href="#fnref:F83" rev=footnote  title="Jump back to footnote 9 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:F83" rev=footnote  title="Jump back to footnote 9 in the text">&#8617;</a><a class=footnote-backref  href="#fnref3:F83" rev=footnote  title="Jump back to footnote 9 in the text">&#8617;</a><a class=footnote-backref  href="#fnref4:F83" rev=footnote  title="Jump back to footnote 9 in the text">&#8617;</a></p> <li id="fn:F85"> <p>G. Frederickson, “Data Structures for On-Line Updating of Minimum Spanning Trees, with Applications,” <em>SIAM J. Comput.</em>, vol. 14, no. 4, pp. 781–798, Nov. 1985.&#160;<a class=footnote-backref  href="#fnref:F85" rev=footnote  title="Jump back to footnote 10 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:F85" rev=footnote  title="Jump back to footnote 10 in the text">&#8617;</a></p> <li id="fn:F97a"> <p>G. Frederickson, “Ambivalent Data Structures for Dynamic 2-Edge-Connectivity and <tex>$k$</tex> Smallest Spanning Trees,” <em>SIAM J. Comput.</em>, vol. 26, no. 2, pp. 484–538, Mar. 1997.&#160;<a class=footnote-backref  href="#fnref:F97a" rev=footnote  title="Jump back to footnote 11 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:F97a" rev=footnote  title="Jump back to footnote 11 in the text">&#8617;</a></p> <li id="fn:F97b"> <p>G. N. Frederickson, “A Data Structure for Dynamically Maintaining Rooted Trees,” <em>Journal of Algorithms</em>, vol. 24, no. 1, pp. 37–65, Jul. 1997.&#160;<a class=footnote-backref  href="#fnref:F97b" rev=footnote  title="Jump back to footnote 12 in the text">&#8617;</a></p> <li id="fn:G91"> <p>A. V. Goldberg, M. D. Grigoriadis, and R. E. Tarjan, “Use of Dynamic Trees in a Network Simplex Algorithm for the Maximum Flow Problem,” <em>Mathematical Programming</em>, vol. 50, no. 1, pp. 277–290, Mar. 1991.&#160;<a class=footnote-backref  href="#fnref:G91" rev=footnote  title="Jump back to footnote 13 in the text">&#8617;</a></p> <li id="fn:H99"> <p>M. R. Henzinger, V. King, and V. King, “Randomized Fully Dynamic Graph Algorithms with Polylogarithmic Time Per Operation,” <em>J. ACM</em>, vol. 46, no. 4, pp. 502–516, Jul. 1999.&#160;<a class=footnote-backref  href="#fnref:H99" rev=footnote  title="Jump back to footnote 14 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:H99" rev=footnote  title="Jump back to footnote 14 in the text">&#8617;</a></p> <li id="fn:K56"> <p>J. B. Kruskal, “On the Shortest Spanning Subtree of a Graph and the Traveling Salesman Problem,” <em>Proc. Amer. Math. Soc.</em>, vol. 7, no. 1, pp. 48–50, 1956.&#160;<a class=footnote-backref  href="#fnref:K56" rev=footnote  title="Jump back to footnote 15 in the text">&#8617;</a></p> <li id="fn:M03"> <p>G. Marsaglia, “Xorshift RNGs,” <em>Journal of Statistical Software</em>, vol. 8, no. 1, pp. 1–6, Jul. 2003.&#160;<a class=footnote-backref  href="#fnref:M03" rev=footnote  title="Jump back to footnote 16 in the text">&#8617;</a></p> <li id="fn:P04"> <p>B. Pfaff, “Performance Analysis of BSTs in System Software,” in <em>Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems</em>, New York, NY, USA, 2004, pp. 410–411.&#160;<a class=footnote-backref  href="#fnref:P04" rev=footnote  title="Jump back to footnote 17 in the text">&#8617;</a></p> <li id="fn:R98"> <p>T. Radzik, “Implementation of Dynamic Trees with In-subtree Operations,” <em>J. Exp. Algorithmics</em>, vol. 3, Sep. 1998.&#160;<a class=footnote-backref  href="#fnref:R98" rev=footnote  title="Jump back to footnote 18 in the text">&#8617;</a></p> <li id="fn:R96"> <p>G. Ramalingam and T. Reps, “On the Computational Complexity of Dynamic Graph Problems,” <em>Theoretical Computer Science</em>, vol. 158, no. 1, pp. 233–277, May 1996.&#160;<a class=footnote-backref  href="#fnref:R96" rev=footnote  title="Jump back to footnote 19 in the text">&#8617;</a></p> <li id="fn:S96"> <p>R. Seidel and C. R. Aragon, “Randomized Search Trees,” <em>Algorithmica</em>, vol. 16, no. 4, pp. 464–497, Oct. 1996.&#160;<a class=footnote-backref  href="#fnref:S96" rev=footnote  title="Jump back to footnote 20 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:S96" rev=footnote  title="Jump back to footnote 20 in the text">&#8617;</a><a class=footnote-backref  href="#fnref3:S96" rev=footnote  title="Jump back to footnote 20 in the text">&#8617;</a></p> <li id="fn:S81"> <p>D. D. Sleator and R. E. Tarjan, “A Data Structure for Dynamic Trees,” in <em>Proceedings of the Thirteenth Annual ACM Symposium on Theory of Computing</em>, New York, NY, USA, 1981, pp. 114–122.&#160;<a class=footnote-backref  href="#fnref:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref3:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref4:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref5:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref6:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref7:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref8:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref9:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref10:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a><a class=footnote-backref  href="#fnref11:S81" rev=footnote  title="Jump back to footnote 21 in the text">&#8617;</a></p> <li id="fn:S85"> <p>D. D. Sleator and R. E. Tarjan, “Self-adjusting Binary Search Trees,” <em>J. ACM</em>, vol. 32, no. 3, pp. 652–686, Jul. 1985.&#160;<a class=footnote-backref  href="#fnref:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a><a class=footnote-backref  href="#fnref3:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a><a class=footnote-backref  href="#fnref4:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a><a class=footnote-backref  href="#fnref5:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a><a class=footnote-backref  href="#fnref6:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a><a class=footnote-backref  href="#fnref7:S85" rev=footnote  title="Jump back to footnote 22 in the text">&#8617;</a></p> <li id="fn:T97"> <p>R. E. Tarjan, “Dynamic Trees as Search Trees via Euler Tours, Applied to the Network Simplex Algorithm,” <em>Mathematical Programming</em>, vol. 78, no. 2, pp. 169–177, Aug. 1997.&#160;<a class=footnote-backref  href="#fnref:T97" rev=footnote  title="Jump back to footnote 23 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:T97" rev=footnote  title="Jump back to footnote 23 in the text">&#8617;</a></p> <li id="fn:T05"> <p>R. E. Tarjan and R. F. Werneck, “Self-Adjusting Top Trees,” in <em>Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, Philadelphia, PA, USA, 2005, pp. 813–822.&#160;<a class=footnote-backref  href="#fnref:T05" rev=footnote  title="Jump back to footnote 24 in the text">&#8617;</a></p> <li id="fn:T10"> <p>R. E. Tarjan and R. F. Werneck, “Dynamic Trees in Practice,” <em>J. Exp. Algorithmics</em>, vol. 14, pp. 5:4.5–5:4.23, Jan. 2010.&#160;<a class=footnote-backref  href="#fnref:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a><a class=footnote-backref  href="#fnref3:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a><a class=footnote-backref  href="#fnref4:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a><a class=footnote-backref  href="#fnref5:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a><a class=footnote-backref  href="#fnref6:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a><a class=footnote-backref  href="#fnref7:T10" rev=footnote  title="Jump back to footnote 25 in the text">&#8617;</a></p> <li id="fn:W06"> <p>R. Werneck, “Design and Analysis of Data Structures for Dynamic Trees,” Princeton University, 2006.&#160;<a class=footnote-backref  href="#fnref:W06" rev=footnote  title="Jump back to footnote 26 in the text">&#8617;</a><a class=footnote-backref  href="#fnref2:W06" rev=footnote  title="Jump back to footnote 26 in the text">&#8617;</a></p> </ol> </div> <hr/> <div id=comments ></div> <script> window.addEventListener('load', () => { quicklink(); }); const gitment = new Gitment({id: 'a9962e7aca2989c02171ea3ad420d451', owner: 'riteme', repo: 'riteme.github.io', oauth: { client_id: 'd4fcffa25858a7a58e1a', client_secret: 'e0c8e08beb95497871f8355416c69390634cec76' }, perPage: 10, }); gitment.render('comments'); </script> </div> </div> <div class="mdl-cell sidebar"> <div class=article > <div class="mdl-card mdl-shadow--2dp sidebar-card"> <div class="mdl-card__actions sidebar-title">页面信息</div> <div class=mdl-card__supporting-text > 标签: <a href="/search.html?q=动态树"><span class=label >动态树</span></a> <a href="/search.html?q=LCT"><span class=label >LCT</span></a> <a href="/search.html?q=Splay"><span class=label >Splay</span></a> <a href="/search.html?q=Treap"><span class=label >Treap</span></a> <a href="/search.html?q=课程论文"><span class=label >课程论文</span></a><br/> 创建时间: 2019.06.13<br/> 上次修改: 2019.06.13<br/> 字数统计: 34256 字 / 约 2 小时 17 分钟 </div> </div> <br/> <div class="mdl-card mdl-shadow--2dp sidebar-card"> <div class="mdl-card__actions sidebar-title">目录</div> <div class=mdl-card__supporting-text > <div class=toc > <ul> <li><a href="#dynamic-trees-with-alternative-search-trees">Dynamic Trees with Alternative Search Trees</a><ul> <li><a href="#1-introduction">1 Introduction</a> <li><a href="#2-dynamic-trees">2 Dynamic Trees</a> <li><a href="#3-reviews-and-analyses">3 Reviews and Analyses</a> <li><a href="#4-experiments">4 Experiments</a> <li><a href="#5-conclusions-and-discussions">5 Conclusions and Discussions</a> <li><a href="#appendixes">Appendixes</a> </ul> </ul> <ul><li><a href="#comments">评论区</a></ul></div> </div> </div> <br/> <div class="mdl-card mdl-shadow--2dp sidebar-card"> <div class="mdl-card__actions sidebar-title">数学公式渲染</div> <div class=mdl-card__supporting-text > <form name=mathopt > <label class="mdl-radio mdl-js-radio" for=option-1 > <input type=radio  id=option-1  class=mdl-radio__button  name=sel  value=mathjax > <span class=mdl-radio__label >MathJax</span> </label><br/> <label class="mdl-radio mdl-js-radio" for=option-2 > <input type=radio  id=option-2  class=mdl-radio__button  name=sel  value=katex > <span class=mdl-radio__label >KaTeX</span> </label> <div id=tip-1 > <label class="mdl-radio mdl-js-radio" for=option-3 > <input type=radio  id=option-3  class=mdl-radio__button  name=sel  value="katex&mathjax"> <span class=mdl-radio__label >Mixed</span> </label> </div> </form> <div id=tip-2 > <label class="mdl-checkbox mdl-js-checkbox" for=mathopt-align > <input type=checkbox  id=mathopt-align  class=mdl-checkbox__input > <span class=mdl-checkbox__label >居中显示</span> </label> </div> </div> </div> <div class=mdl-tooltip  data-mdl-for=tip-1 >先使用 KaTeX 渲染，再使用 MathJax 渲染</div> <div class=mdl-tooltip  data-mdl-for=tip-2 >该选项目前仅支持 KaTeX 渲染的公式<br/>点击公式可以切换单个公式的对齐方式</div> <br/> <div class="nano mdl-card mdl-shadow--2dp sidebar-card"> <div class=mdl-card__actions > <div class=nano-shell ><span class=shell-start >$</span> nano <a href="https://github.com/riteme/riteme.github.io/blob/master/blog/2019-6-13/dynamic-trees-eap.md" id=nano-link >dynamic-trees-eap.md</a></div> </div> </div> <div class=mdl-tooltip  data-mdl-for=nano-link >查看原始 Markdown 文档</div> </div> </div> </div> <footer class=mdl-mega-footer > <div class=mdl-mega-footer__middle-section > <div class=mdl-mega-footer__drop-down-section > <input class=mdl-mega-footer__heading-checkbox  type=checkbox  checked> <h2 class=mdl-mega-footer__heading >RITEME.SITE</h2><del>一个从不乱说话的博客</del> </div> <div class=mdl-mega-footer__drop-down-section > <input class=mdl-mega-footer__heading-checkbox  type=checkbox  checked> <h2 class=mdl-mega-footer__heading >POWERED BY</h2> <ul class=mdl-mega-footer__link-list > <li><a href="http://pythonhosted.org/Markdown/">Python Markdown</a> <li><a href="http://getmdl.io/">Material Design Lite</a> <li><a href="http://www.tipue.com/search/">Tipuesearch</a> <li><a href="http://www.mathjax.org/">MathJax</a> & <a href="http://khan.github.io/KaTeX/">KaTeX</a> <li><a href="https://github.com/imsun/gitment">Gitment</a> </ul> </div> <div class=mdl-mega-footer__drop-down-section > <input class=mdl-mega-footer__heading-checkbox  type=checkbox  checked> <h2 class=mdl-mega-footer__heading >友情链接</h2> <ul class=mdl-mega-footer__link-list > <li><a href="http://ruanx.pw/">ruanxingzhi</a> <li><a href="https://blog.xehoth.cc/">xehoth</a> <li><a href="http://hjwjbsr.is-programmer.com/">HJWJBSR</a> <li><a href="http://www.micdz.cn/">MicDZ</a> <li><a href="https://cmxrynp.github.io/">CMXRYNP</a> <li><a href="http://memset0.cn/">memset0</a> </ul> </div> </div> <div class=mdl-mega-footer__bottom-section >Theme based on <a href="https://getmdl.io/">MDL</a> | <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" class=cc  src="/assets/cc-by-nc-sa-4.png" /></a> CC BY-NC-SA 4.0 </div> </footer> </main> </div>
